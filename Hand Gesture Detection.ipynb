{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7acfb3c",
   "metadata": {},
   "source": [
    "## Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54b6c1e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: cvzone in c:\\users\\kiit\\anaconda3\\lib\\site-packages (1.5.6)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\kiit\\anaconda3\\lib\\site-packages (from cvzone) (4.7.0.72)\n",
      "Requirement already satisfied: numpy in c:\\users\\kiit\\anaconda3\\lib\\site-packages (from cvzone) (1.23.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install cvzone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b61f4632",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyautogui in c:\\users\\kiit\\anaconda3\\lib\\site-packages (0.9.53)\n",
      "Requirement already satisfied: pymsgbox in c:\\users\\kiit\\anaconda3\\lib\\site-packages (from pyautogui) (1.0.9)\n",
      "Requirement already satisfied: PyTweening>=1.0.1 in c:\\users\\kiit\\anaconda3\\lib\\site-packages (from pyautogui) (1.0.4)\n",
      "Requirement already satisfied: pyscreeze>=0.1.21 in c:\\users\\kiit\\anaconda3\\lib\\site-packages (from pyautogui) (0.1.28)\n",
      "Requirement already satisfied: pygetwindow>=0.0.5 in c:\\users\\kiit\\anaconda3\\lib\\site-packages (from pyautogui) (0.0.9)\n",
      "Requirement already satisfied: mouseinfo in c:\\users\\kiit\\anaconda3\\lib\\site-packages (from pyautogui) (0.1.3)\n",
      "Requirement already satisfied: pyrect in c:\\users\\kiit\\anaconda3\\lib\\site-packages (from pygetwindow>=0.0.5->pyautogui) (0.2.0)\n",
      "Requirement already satisfied: pyperclip in c:\\users\\kiit\\anaconda3\\lib\\site-packages (from mouseinfo->pyautogui) (1.8.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pyautogui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a077a1e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in c:\\users\\kiit\\anaconda3\\lib\\site-packages (4.7.0.72)\n",
      "Requirement already satisfied: numpy>=1.17.0 in c:\\users\\kiit\\anaconda3\\lib\\site-packages (from opencv-python) (1.23.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install opencv-python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67faed66",
   "metadata": {},
   "source": [
    "**Above mentioned libraries required for Gestures Detection.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b820bb88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# computer vision library\n",
    "import cvzone\n",
    "\n",
    "# HandTrackingModule within cvzone allows you to easily detect hands and their landmarks\n",
    "from cvzone.HandTrackingModule import HandDetector\n",
    "\n",
    "#  Used for image and video processing from Opencv.\n",
    "import cv2 \n",
    "\n",
    "# pyautogui is a library that allows you to programmatically control the mouse and keyboard on your computer.\n",
    "import pyautogui as auto"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d867b88",
   "metadata": {},
   "source": [
    "* The HandTrackingModule within cvzone allows you to easily detect hands and their landmarks in an image or video stream, making it convenient for hand tracking applications like gesture recognition or controlling applications with hand gestures.\n",
    "\n",
    "* OpenCV provides a wide range of functions and tools for image and video processing, feature detection, object recognition, and other computer vision-related tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c89c0a18",
   "metadata": {},
   "source": [
    "* pyautogui is a library that allows you to programmatically control the mouse and keyboard on your computer.\n",
    "    - It is useful for automating repetitive tasks, creating scripts that interact with graphical user interfaces, or even creating bots for games or other applications that require user input.\n",
    "    - The library supports various platforms, making it cross-platform compatible, and it provides simple and easy-to-use functions for simulating keyboard keypresses, mouse movements, and clicks.\n",
    "    - PyAutoGUI can be used for various automation and simulation purposes, including GUI testing, data entry, and other tasks that require emulating user interactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab669d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "using the cvzone library for hand tracking and pyautogui for simulating keyboard presses. \n",
    "It is meant to detect hand gestures in real-time using the webcam and perform a specific action when the \n",
    "distance between two fingers is less than 25 pixels.\n",
    "\"\"\"\n",
    "\n",
    "# Initializes the webcam and captures video from the default camera (index 0).\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# detectionCon=0.8: The confidence threshold for hand detection\n",
    "detector = HandDetector(detectionCon=0.8, maxHands=1)\n",
    "\n",
    "while True:\n",
    "    #  Captures a frame from the webcam and stores it in the variable img.\n",
    "    success, img = cap.read()\n",
    "    hands, img = detector.findHands(img, draw=True)\n",
    "\n",
    "    if hands:\n",
    "        # Hand 1\n",
    "        hand1 = hands[0]\n",
    "        \n",
    "        # Extracts the landmark points (coordinates) of the detected hand.\n",
    "        HandLandMarkList1 = hand1[\"lmList\"]  # List of 21 Landmark points\n",
    "        \n",
    "        # Calcuulate the distance between two specific landmarks\n",
    "        length,info,frame = detector.findDistance(HandLandMarkList1[4][0:2],HandLandMarkList1[8][0:2],img)\n",
    "        \n",
    "        # Rounds the distance to the nearest integer.\n",
    "        length = round(length)\n",
    "        \n",
    "        \"\"\" When the distance between the thumb and the index finger is less than 25 pixels, \n",
    "        the code simulates pressing the 'up' key.\"\"\"\n",
    "        if length<25:\n",
    "            auto.press('up')\n",
    "\n",
    "    cv2.imshow(\"Image\", img)\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a6a7e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ddc3ef5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b3152b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24d09d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbdca0a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ffea014f",
   "metadata": {},
   "source": [
    "the code continuously captures frames from the webcam, detects and tracks a hand in the frame, calculates the distance between specific landmarks on the hand, and performs a keyboard action (simulating the \"up\" arrow key press) based on the calculated distance. This code serves as a basic example of real-time hand gesture recognition and can be further extended to create more complex interactions with the computer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e815ff0d",
   "metadata": {},
   "source": [
    "Importing Libraries:\n",
    "\n",
    "cvzone: This is the library that provides additional functionalities on top of OpenCV, specifically for computer vision tasks.\n",
    "HandDetector from cvzone.HandTrackingModule: This is a class provided by the cvzone library that enables hand tracking and gesture detection.\n",
    "cv2: This is the OpenCV library used for image and video processing.\n",
    "pyautogui: This is a library used for controlling the keyboard and mouse to perform tasks on the computer.\n",
    "Video Capture Setup:\n",
    "\n",
    "cap = cv2.VideoCapture(0): Initializes the webcam and captures video from the default camera (index 0).\n",
    "Hand Detector Initialization:\n",
    "\n",
    "detector = HandDetector(detectionCon=0.8, maxHands=1): Creates an instance of the HandDetector class with specific parameters.\n",
    "detectionCon=0.8: The confidence threshold for hand detection. It sets the minimum confidence level for considering a detected region as a hand.\n",
    "maxHands=1: Limits the number of hands to be detected. Here, we set it to 1, indicating that we are only interested in detecting one hand."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b105b462",
   "metadata": {},
   "source": [
    "The importance of detecting landmarks in the above project lies in its ability to track and recognize specific points on the hand, which enables various functionalities and applications:\n",
    "\n",
    "Gesture Recognition: By detecting hand landmarks, the system can recognize different hand gestures made by the user. This can be utilized in controlling applications, games, or devices with specific hand movements. For example, making a \"thumbs-up\" gesture to give a positive response or a \"peace sign\" gesture to execute a specific action.\n",
    "\n",
    "Hand Tracking: The landmark detection allows real-time tracking of the user's hand. This is valuable in applications where the movement of the hand needs to be monitored continuously, such as in virtual reality or augmented reality experiences.\n",
    "\n",
    "Interaction with Virtual Elements: By tracking hand landmarks, the system can map the position of the hand in a virtual space. This enables users to interact with virtual elements or objects using their hands, enhancing the user experience and making it more intuitive.\n",
    "\n",
    "Sign Language Recognition: Hand landmark detection can be used in applications that aim to interpret sign language. This can aid in improving communication and accessibility for people with hearing impairments.\n",
    "\n",
    "Hand Gesture Control: Hand gestures can be mapped to specific commands or actions in an application. This allows for hands-free control of systems, such as controlling a presentation by gesturing instead of using traditional input devices.\n",
    "\n",
    "Gaming: Hand landmark detection can be utilized in gaming applications to introduce more immersive and interactive gameplay experiences. For example, controlling a character in a game using hand gestures.\n",
    "\n",
    "Human-Computer Interaction: By recognizing hand landmarks, the project facilitates natural and intuitive interactions between users and computers. This can lead to more user-friendly and efficient user interfaces.\n",
    "\n",
    "In summary, hand landmark detection in the project plays a crucial role in enabling various functionalities that enhance user interactions, facilitate gesture-based controls, and provide new and innovative ways for users to interact with technology. This technology has a wide range of applications in diverse fields, from gaming and virtual reality to accessibility and human-computer interaction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eff25bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
